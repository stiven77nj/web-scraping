# üì¶ API REST - Web Scraping

Esta API REST construida con **Express.js** permite realizar **peticiones GET** para ejecutar procesos de **web scraping** sobre distintas p√°ginas, cada una representada por un endpoint espec√≠fico. Actualmente se utiliza para extraer informaci√≥n de las plataformas **Mercately** y **ApiCrops**.

## üöÄ Tecnolog√≠as utilizadas

- **Express.js** ‚Äì Framework para construir la API REST.
- **Puppeteer** ‚Äì Librer√≠a de Node.js que permite automatizar el navegador para realizar scraping.
- **Docker** ‚Äì Contenedor para ejecutar la aplicaci√≥n de forma portable.
- **SQL Server** ‚Äì Base de datos relacional para almacenar la informaci√≥n extra√≠da.

## üåê P√°ginas objetivo de scraping

Se accede al CRM de Mercately para descargar datos de clientes autom√°ticamente:

> [https://app.mercately.com/login](https://app.mercately.com/login)

Se accede a la p√°gina para extraer informacion del clima y de suelo:

> [https://web.instacrops.com](https://web.instacrops.com)

## ‚öôÔ∏è Estructura del Proyecto

- /api
- /config
- /downloads
- /src
- .env # Variables de entorno (credenciales, configuraciones)
- Dockerfile # Imagen de Docker para contener la app

## üì¶ Instalaci√≥n

1. Clona el repositorio:

```bash
$ git clone https://github.com/stiven77nj/web-scraping.git
$ cd web-scraping
```

2. Instala las dependencias:

```bash
npm install
```

3. Configura el archivo .env:

```bash
# CREDENCIALES MERCATELY
MERCATELY_USER=UsuarioMercately
MERCATELY_PASSWORD=ClaveMercately
MERCATELY_BASE_URL=https://url.com
MERCATELY_DOWNLOAD_DIR=./downloads/mercately

# CREDENCIALES MERCATELY
API_CROPS_USER=UsuarioApiCrops
API_CROPS_PASSWORD=ClaveApiCrops
API_CROPS_BASE_URL=https://url.com
API_CROPS_DOWNLOAD_DIR=downloads/api_crops/


# VARIABLES API REST - EXPRESS
PORT_API=0000
```

4. Ejecuta la API localmente:

```bash
npm run dev
```

## üê≥ Uso con Docker

```bash
docker build -t scraping-api .
docker run -p 8081:8081 scraping-api
```

## üîå Endpoints disponibles

- GET /api/mercately ‚Äì Ejecuta el proceso de scraping para obtener informe clientes desde Mercately.

## üóÉÔ∏è Base de datos

Los datos extra√≠dos se almacenan autom√°ticamente en una instancia de SQL Server.

## Estado actual

- ‚úÖ Estado actual
- ‚úÖ Login automatizado con Puppeteer
- ‚úÖ Descarga de archivo Excel desde CRM
- ‚úÖ Parseo del archivo y carga en SQL Server
- ‚úÖ Soporte para m√∫ltiples plataformas
- ‚åõ Manejo de errores m√°s robusto
- ‚åõ Testing automatizado